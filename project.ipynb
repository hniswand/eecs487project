{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bored-graduation",
   "metadata": {
    "id": "bored-graduation"
   },
   "source": [
    "# EECS 487 Project: Naive Bayes Classifier of Sentiment Analysis of Contraseptives\n",
    "\n",
    "This notebook contains the code of our project. In the second problem, you will build naive bayes classifiers to distinguish between legitimate news headlines and clickbait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "angry-large",
   "metadata": {
    "id": "angry-large"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/yousolbae/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/yousolbae/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/yousolbae/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/yousolbae/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/yousolbae/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk --upgrade  # after running this line once, you can comment this line out\n",
    "import nltk\n",
    "print(nltk.__version__) # this should print out 3.8.1 if you have installed the latest version of NLTK properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ec2d2",
   "metadata": {
    "id": "6e6ec2d2"
   },
   "source": [
    "Before we get started, run the following cell to load the autoreload extension so that functions in ```language_model.py``` and ```naive_bayes.py``` will be re-imported into the notebook every time we run them. We also need to import all necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94ca6b2e",
   "metadata": {
    "id": "94ca6b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from naive_bayes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-poison",
   "metadata": {
    "id": "regular-poison"
   },
   "source": [
    "## C.2 Naive Bayes for Text Classification [26 points]\n",
    "In this problem, you will build naive bayes classifiers to do text classification. You will use the clickbait headlines dataset, which contains examples of legitimate news headlines and clickbait news headlines. The original dataset can be found in [this GitHub repository](https://github.com/bhargaviparanjape/clickbait) and [this paper](https://arxiv.org/abs/1610.09786).\n",
    "### C.2.1 Load dataset [4 points]\n",
    "To get started, **fill in** the function ```load_headlines``` to load the clickbait dataset into pandas dataframes. The file ```clickbait_data.csv``` contains a partially processed subset of the data. It contains two columns: (1) ```is_clickbait``` is 1 when the row contains a clickbait headline and 0 when it doesn't and (2) ```text```, which contains the headline itself.\n",
    "\n",
    "To get started, **fill in** the function ```load_headlines``` to load the clickbait dataset into a pandas dataframe. To do this, you will need to do the following:\n",
    "\n",
    "1. Read in the ```text``` and ```is_clickbait``` columns.\n",
    "2. Rename the ```is_clickbait``` column to ```label```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "realistic-execution",
   "metadata": {
    "id": "realistic-execution"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10174</th>\n",
       "      <td>3</td>\n",
       "      <td>I was on this med in my twenties and it worked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>5</td>\n",
       "      <td>I've been taking this pill for over 5 months n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>5</td>\n",
       "      <td>I actually got on this site to see hwta other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>1</td>\n",
       "      <td>I was only on this pill 2 weeks when I woke on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14315</th>\n",
       "      <td>5</td>\n",
       "      <td>I took Demulen for many years at the referral ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>1</td>\n",
       "      <td>After having been on cyclessa (a triphasic pil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10246</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm taking Apri since  1 1/2 year and I never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13757</th>\n",
       "      <td>5</td>\n",
       "      <td>I have been on this BC pill for about 6 months...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>4</td>\n",
       "      <td>So far, I'm having BAD nausea.  I feel like I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10115 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ratings                                            reviews\n",
       "10174        3  I was on this med in my twenties and it worked...\n",
       "7997         5  I've been taking this pill for over 5 months n...\n",
       "3180         5  I actually got on this site to see hwta other ...\n",
       "3218         1  I was only on this pill 2 weeks when I woke on...\n",
       "831          5                                                   \n",
       "...        ...                                                ...\n",
       "14315        5  I took Demulen for many years at the referral ...\n",
       "3631         1  After having been on cyclessa (a triphasic pil...\n",
       "10246        5  I'm taking Apri since  1 1/2 year and I never ...\n",
       "13757        5  I have been on this BC pill for about 6 months...\n",
       "2649         4  So far, I'm having BAD nausea.  I feel like I ...\n",
       "\n",
       "[10115 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>4</td>\n",
       "      <td>I was placed on this medication for the follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7142</th>\n",
       "      <td>4</td>\n",
       "      <td>abnormal bleeding.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>5</td>\n",
       "      <td>I guess I may be a bit different from the othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>5</td>\n",
       "      <td>I almost backed out of getting Mirena because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12528</th>\n",
       "      <td>5</td>\n",
       "      <td>I received a supply of this pill from Planned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>5</td>\n",
       "      <td>I had the Mirena put in on my 6 week check up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10460</th>\n",
       "      <td>1</td>\n",
       "      <td>This medication caused massive and sub-massive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9609</th>\n",
       "      <td>5</td>\n",
       "      <td>I've been taking aviane for two years now. I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882</th>\n",
       "      <td>5</td>\n",
       "      <td>I love the drug.  However. Ive gained twenty f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11013</th>\n",
       "      <td>3</td>\n",
       "      <td>I started this pill regime (Quasense) on May 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4335 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ratings                                            reviews\n",
       "5391         4  I was placed on this medication for the follow...\n",
       "7142         4                                 abnormal bleeding.\n",
       "7324         5  I guess I may be a bit different from the othe...\n",
       "264          5  I almost backed out of getting Mirena because ...\n",
       "12528        5  I received a supply of this pill from Planned ...\n",
       "...        ...                                                ...\n",
       "653          5  I had the Mirena put in on my 6 week check up ...\n",
       "10460        1  This medication caused massive and sub-massive...\n",
       "9609         5  I've been taking aviane for two years now. I h...\n",
       "5882         5  I love the drug.  However. Ive gained twenty f...\n",
       "11013        3  I started this pill regime (Quasense) on May 1...\n",
       "\n",
       "[4335 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from naive_bayes import *\n",
    "\n",
    "all_data = load_headlines('reviews.csv')\n",
    "\n",
    "(train, test) = train_test_split(all_data, train_size=0.7)\n",
    "\n",
    "display(train)\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-spank",
   "metadata": {
    "id": "earlier-spank"
   },
   "source": [
    "### C.2.2 Dataset statistics [3 points]\n",
    "Before start training classifiers, you need to calculate some basic statistics of the dataset. **Fill in** the function ```get_basic_stats``` to print out the following statistics of the training data:\n",
    "- Average number of tokens per headline\n",
    "- Standard deviation of the number of tokens per headline\n",
    "- Total number of legitimate headlines\n",
    "- Total number of clickbait headlines\n",
    "\n",
    "Note: you can use any tokenization method you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "sticky-account",
   "metadata": {
    "id": "sticky-account"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tokens per headline: 110.13079584775086\n",
      "Standard deviation: 77.16307487574683\n",
      "Number of negative/positive headlines: {0: 3537, 1: 10913}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 3537, 1: 10913}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_basic_stats(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-rental",
   "metadata": {
    "id": "exterior-rental"
   },
   "source": [
    "### C.2.3 Data processing and ngram calculation [6 points]\n",
    "Now you need to calculate the ngram counts. **Fill in** the function ```fit``` that, given a dataframe of training data, calculates the ngram counts in each category and the prior probability for each category. Concretely, **store** the total occurrence of each ngram in each category in a list called ```self.ngram_count``` so that ```self.ngram_count[0]``` contains $count(w, c_0)$ for all $w$ in the vocabulary, and ```self.ngram_count[1]``` contains $count(w, c_1)$, etc. ```self.ngram_count[i]``` should be an array of shape $(1,|V|)$, where $V$ is the vocabulary (total vocabulary across both classes). **Store** the total occurrence of all ngrams in each category in a list called ```self.total_count``` so that ```self.total_count[0]``` $=\\sum_{w\\in V}count(w, c_0)$, and ```self.total_count[1]``` $=\\sum_{w\\in V}count(w, c_1)$, etc. **Store** the prior probability for each category in ```self.category_prob```. You need to follow these rules when calculating the counts:\n",
    "- convert all letters to lowercase;\n",
    "- include both unigrams and bigrams;\n",
    "- ignore terms that appear in more than 80\\% of the headlines;\n",
    "- ignore terms that appear in less than 3 headlines.\n",
    "\n",
    "Hint: use ```CountVectorizer``` in sklearn and store it as ```self.vectorizer```. You need to use **both legitimate and clickbait headlines** to get the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "personalized-opening",
   "metadata": {
    "id": "personalized-opening"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for each category: [0.24290657 0.75709343]\n",
      "Length of self.ngram_count: 2\n",
      "Shape of the counts for 1st category: (46931,)\n",
      "Number of non-zero terms for 1st category: 35660\n",
      "Maximum count of the 1st category: 6931.0\n",
      "Minimum count of the 1st category: 0.0\n",
      "Sum of ngram count for 1st category: 365251.0\n",
      "Total count for each category: [ 365251. 1203534.]\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = NaiveBayes()\n",
    "naive_bayes.fit(train)\n",
    "print(f\"Probability for each category: {naive_bayes.category_prob}\")\n",
    "print(f\"Length of self.ngram_count: {len(naive_bayes.ngram_count)}\")\n",
    "print(f\"Shape of the counts for 1st category: {naive_bayes.ngram_count[0].shape}\")\n",
    "print(f\"Number of non-zero terms for 1st category: {(naive_bayes.ngram_count[0] > 0).sum()}\")\n",
    "print(f\"Maximum count of the 1st category: {naive_bayes.ngram_count[0].max()}\")\n",
    "print(f\"Minimum count of the 1st category: {naive_bayes.ngram_count[0].min()}\")\n",
    "print(f\"Sum of ngram count for 1st category: {naive_bayes.ngram_count[0].sum()}\")\n",
    "print(f\"Total count for each category: {naive_bayes.total_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-decimal",
   "metadata": {
    "id": "blind-decimal"
   },
   "source": [
    "### C.2.4 Calculate posterior probability for a category [4 points]\n",
    "Next, you will use the vectorizer and ngram counts to calculate the posterior probability of a category. In this homework, we have two categories: legitimate and clickbait. **Fill in** the function ```calculate_prob``` that given a list of articles $docs$, a category index $i$, return $\\log\\left(p(c_i)p(d|c_i)\\right)=\\log\\left(p(c_i)\\prod_{x\\in X}p(x|c_i)\\right)$ for each article $d$ in $docs$, where $X$ is the set of unigrams and bigrams in **both** article $d$ and vocabulary $V$.\n",
    "\n",
    "- Use **add-one smoothing** in your calculation.\n",
    "- Simply discard unseen unigrams/bigrams (do not use add-one smoothing to account for them).\n",
    "- Calculate the **sum of logarithms** to avoid issues with underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "brave-determination",
   "metadata": {
    "id": "brave-determination"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for category 0: [-17.33100299 -96.63015648]\n",
      "Probability for category 1: [-16.00840133 -94.23799538]\n"
     ]
    }
   ],
   "source": [
    "test_docs = [\"United Kingdom officially exits the European Union\",\n",
    " \"How to Lose a Guy in 10 Days\"]\n",
    "prob1 = naive_bayes.calculate_prob(test_docs, 0)\n",
    "prob2 = naive_bayes.calculate_prob(test_docs, 1)\n",
    "print(f\"Probability for category 0: {prob1}\")\n",
    "print(f\"Probability for category 1: {prob2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-sheep",
   "metadata": {
    "id": "occupied-sheep"
   },
   "source": [
    "### C.2.5 Predict labels for new headlines [2 points]\n",
    "With the posterior probability of each category, you can predict the label for new headlines. **Fill in** the function ```predict``` that, given a list of headlines, returns the predicted categories of the headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "opposed-territory",
   "metadata": {
    "id": "opposed-territory"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1, 1]\n"
     ]
    }
   ],
   "source": [
    "preds = naive_bayes.predict(test_docs)\n",
    "print(f\"Prediction: {preds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-semester",
   "metadata": {
    "id": "bronze-semester"
   },
   "source": [
    "### C.2.6 Calculate evaluation metrics [5 points]\n",
    "To evaluate a classifier, you need to calculate some evaluation metrics. **Fill in** the function ```evaluate``` that, given a list of predictions and a list of true labels, returns the accuracy, macro f1-score, and micro f1-score. You can **NOT** use functions in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "level-casino",
   "metadata": {
    "id": "level-casino"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7142857142857143\n",
      "Macro f1: 0.7083333333333333\n",
      "Micro f1: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "predictions = [1,1,0,1,0,0,1]\n",
    "labels = [1,0,0,1,0,1,1]\n",
    "accuracy, mac_f1, mic_f1 = evaluate(predictions, labels)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Macro f1: {mac_f1}\")\n",
    "print(f\"Micro f1: {mic_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-corner",
   "metadata": {
    "id": "warming-corner"
   },
   "source": [
    "### C.2.7 Test classifier on test data [2 points]\n",
    "Finally, you are ready to evaluate your classifier on the test data! Run the following cell to make predictions and print out performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "amended-angle",
   "metadata": {
    "id": "amended-angle"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.959\n",
      "Macro f1: 0.9589999589999589\n",
      "Micro f1: 0.959\n"
     ]
    }
   ],
   "source": [
    "predictions = naive_bayes.predict(test.text.tolist())\n",
    "labels = test.label.tolist()\n",
    "accuracy, mac_f1, mic_f1 = evaluate(predictions, labels)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Macro f1: {mac_f1}\")\n",
    "print(f\"Micro f1: {mic_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eabcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
